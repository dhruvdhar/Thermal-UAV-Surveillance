# -*- coding: utf-8 -*-
"""Copy of Welcome to Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ja-lIOh9pitVyZ_vQ4xa8PbBVogQLzRL
"""

!pip install ultralytics opencv-python matplotlib
!pip install torch torchvision
!pip install scikit-learn

from google.colab import files
uploaded = files.upload()  # Upload your `archive.zip`

!unzip archive.zip -d dataset/

!unzip "archive (1).zip" -d /tmp/dataset_raw/

!ls /tmp/dataset_raw

!mkdir -p /tmp/dataset
!mv /tmp/dataset_raw/hit-uav/* /tmp/dataset/

!ls /tmp/dataset/images/train | head
!ls /tmp/dataset/labels/train | head

yaml_text = '''
path: /tmp/dataset
train: images/train
val: images/val
test: images/test
names:
  0: Person
  1: Car
  2: Bicycle
  3: OtherVehicle
  4: DontCare
nc: 5
'''

with open("data.yaml", "w") as f:
    f.write(yaml_text)

from ultralytics import YOLO
model = YOLO('yolov8n.pt')
model.train(data='data.yaml', epochs=1, imgsz=640)

import cv2
import os
from ultralytics import YOLO

# Load trained YOLOv8 model
model = YOLO('runs/detect/train/weights/best.pt')

# Output directory where cropped images will go
output_base = 'cropped_dataset/train'  # for training
os.makedirs(output_base, exist_ok=True)

# Get test images directory
test_dir = '/tmp/dataset/images/test'

# Get class names from the model (e.g., {0: 'Car', 1: 'Person', ...})
class_names = model.names

# Create class-based folders
for cls_name in class_names.values():
    os.makedirs(os.path.join(output_base, cls_name), exist_ok=True)

# Run inference and crop into class folders
for img_file in os.listdir(test_dir):
    img_path = os.path.join(test_dir, img_file)
    img = cv2.imread(img_path)
    results = model(img)

    for i, (box, cls_id) in enumerate(zip(results[0].boxes.xyxy, results[0].boxes.cls)):
        x1, y1, x2, y2 = map(int, box)
        class_name = class_names[int(cls_id)]
        cropped = img[y1:y2, x1:x2]

        save_path = f"{output_base}/{class_name}/{img_file.split('.')[0]}_crop{i}.jpg"
        cv2.imwrite(save_path, cropped)

import torch.nn as nn

class ThermalCNN(nn.Module):
    def __init__(self, dropout=0.3, filters=32):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1, filters, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(filters, filters*2, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(filters*2*32*32, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 4)  # 4 classes
        )

    def forward(self, x):
        return self.fc(self.conv(x))

import numpy as np
import torch
import torch.nn as nn
def evaluate(params, train_loader, val_loader, device):
    model = ThermalCNN(dropout=params[0], filters=int(params[1])).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=params[2])
    criterion = nn.CrossEntropyLoss()

    for epoch in range(2):
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            loss = criterion(model(xb), yb)
            loss.backward()
            optimizer.step()

    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for xb, yb in val_loader:
            xb, yb = xb.to(device), yb.to(device)
            preds = model(xb).argmax(dim=1)
            correct += (preds == yb).sum().item()
            total += yb.size(0)
    return correct / total

def MGO(train_loader, val_loader, device, population_size=10, max_iter=10):
    pop = np.random.rand(population_size, 3)
    pop[:, 0] = np.random.uniform(0.1, 0.5, population_size)  # dropout
    pop[:, 1] = np.round(np.random.uniform(16, 128, population_size))  # filters
    pop[:, 2] = np.random.uniform(0.0001, 0.01, population_size)  # learning rate

    best_score, best_params = 0, None
    for _ in range(max_iter):
        for p in pop:
            acc = evaluate(p, train_loader, val_loader, device)
            if acc > best_score:
                best_score, best_params = acc, p
        pop += np.random.normal(0, 0.01, pop.shape)
        pop[:, 0] = np.clip(pop[:, 0], 0.1, 0.5)
        pop[:, 1] = np.clip(np.round(pop[:, 1]), 16, 128)
        pop[:, 2] = np.clip(pop[:, 2], 0.0001, 0.01)
    return best_params

import os
import shutil

empty_classes = ["cropped_dataset/train/DontCare", "cropped_dataset/train/OtherVehicle"]
for folder in empty_classes:
    if os.path.exists(folder) and not os.listdir(folder):
        shutil.rmtree(folder)
        print(f"Deleted empty class folder: {folder}")

train_ds = datasets.ImageFolder("cropped_dataset/train", transform=transform)

from torchvision import datasets, transforms
from torch.utils.data import DataLoader

transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

train_ds = datasets.ImageFolder("cropped_dataset/train", transform=transform)
train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)

from torch.utils.data import random_split

# 1. Split the dataset
val_size = int(0.2 * len(train_ds))
train_size = len(train_ds) - val_size
train_ds_split, val_ds_split = random_split(train_ds, [train_size, val_size])

train_dl_split = DataLoader(train_ds_split, batch_size=32, shuffle=True)
val_dl_split = DataLoader(val_ds_split, batch_size=32)

# 2. Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# 3. Run MGO to get best hyperparameters
best_params = MGO(train_dl_split, val_dl_split, device, population_size=5, max_iter=5)
print("Best Parameters from MGO:")
print(f"Dropout: {best_params[0]:.4f}, Filters: {int(best_params[1])}, LR: {best_params[2]:.6f}")

# 4. Train final model with best hyperparameters
final_acc = evaluate(best_params, train_dl_split, val_dl_split, device)
print(f"Final Validation Accuracy: {final_acc*100:.2f}%")